{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertisement By JACEY FORTINDEC. 31, 2017  In Sydney, rainbow fireworks sparkled off the Harbour Bridge in celebration of Australia’s recent legalization of gay marriage. (Sydney was among the first major cities to celebrate with fireworks at the stroke of midnight.) In Japan, people paraded in fox masks to attend the first prayer of the year at a Shinto shrine in Tokyo. In the Philippines, revelers gathered — phones in hand — at the Eastwood Mall in Manila to watch balloons and confetti rain down at midnight. Big pots of tea were prepared for New Year’s Eve celebrations in Beijing. The country will also celebrate the Lunar New Year, in February. It was raining in Singapore, but New Year’s Eve celebrants sheltered under umbrellas and raincoats as fireworks sparkled overhead. Tourists donned party hats to watch fireworks in front of the famous Petronas Twin Towers in Kuala Lumpur, Malaysia. Hundreds of couples got married at a mass wedding in Jakarta on New Year’s Eve. We’re interested in your feedback on this page. Tell us what you think. Go to Home Page »\n"
     ]
    }
   ],
   "source": [
    "# open the new dataset\n",
    "\n",
    "import codecs, nltk\n",
    "\n",
    "article = codecs.open(\"../datasets/CleanedArticles/15.txt\",\"r\",\"utf-8\")\n",
    "article = article.read()\n",
    "\n",
    "print (article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31, 2017  In Sydney, rainbow fireworks sparkled off the Harbour Bridge in celebration of Australia’s recent legalization of gay marriage.\n"
     ]
    }
   ],
   "source": [
    "# split into sentences\n",
    "sentences = nltk.sent_tokenize(article) \n",
    "\n",
    "# take one single sentence \n",
    "\n",
    "sentence = sentences[1]\n",
    "\n",
    "print (sentence) # type = string (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', ',', '2017', 'In', 'Sydney', ',', 'rainbow', 'fireworks', 'sparkled', 'off', 'the', 'Harbour', 'Bridge', 'in', 'celebration', 'of', 'Australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage', '.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenizer\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "print (tokenized_sentence) # type = list; each item is now a token, which is our unit of analysis. Numbers are seen as strings, so must tell it that they are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', ',', '2017', 'in', 'sydney', ',', 'rainbow', 'fireworks', 'sparkled', 'off', 'the', 'harbour', 'bridge', 'in', 'celebration', 'of', 'australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage', '.']\n"
     ]
    }
   ],
   "source": [
    "# lowering words\n",
    "\n",
    "lowercased_sentence = [word.lower() for word in tokenized_sentence]\n",
    "# Why useful? Depends on what you want to do...if you want to keep Bush and bush separate, don't lowercase.\n",
    "print (lowercased_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# without punctuation\n",
    "\n",
    "import string\n",
    "\n",
    "# defining punctuation to be removed\n",
    "punctuation = list(string.punctuation)\n",
    "\n",
    "print (punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', '2017', 'in', 'sydney', 'rainbow', 'fireworks', 'sparkled', 'off', 'the', 'harbour', 'bridge', 'in', 'celebration', 'of', 'australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage']\n"
     ]
    }
   ],
   "source": [
    "without_punct_sentence = [token for token in lowercased_sentence if token not in punctuation]\n",
    "# be careful not to remove punctuation that you care about, e.g. @ symbol for symbols or other things important for the type of text you're analyzing\n",
    "print (without_punct_sentence)\n",
    "\n",
    "# missing apostrophe from punctuation string list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# getting stopword list from nltk\n",
    "# check here for the download: https://stackoverflow.com/questions/41610543/corpora-stopwords-not-found-when-import-nltk-library\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word_list = stopwords.words('english')\n",
    "\n",
    "print (stop_word_list)\n",
    "\n",
    "# stop words depend on you and what you want to do; if in your context you care about these words, define your own manual stop words or don't remove stop words\n",
    "# make sure to clarify in paper you write about what the stop words are; don't just use frequent words, be careful how you do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', '2017', 'sydney', 'rainbow', 'fireworks', 'sparkled', 'harbour', 'bridge', 'celebration', 'australia', '’', 'recent', 'legalization', 'gay', 'marriage']\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords\n",
    "\n",
    "without_stopwords_sentence = [word for word in without_punct_sentence if word not in stop_word_list]\n",
    "\n",
    "print (without_stopwords_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sydney', 'rainbow', 'fireworks', 'sparkled', 'harbour', 'bridge', 'celebration', 'australia', 'recent', 'legalization', 'gay', 'marriage']\n"
     ]
    }
   ],
   "source": [
    "# keeping words (alpha is a \"word\" not a number)\n",
    "\n",
    "only_words_sentence = [word for word in without_stopwords_sentence if word.isalpha()]\n",
    "\n",
    "print (only_words_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sydney', 'rainbow', 'firework', 'sparkl', 'harbour', 'bridg', 'celebr', 'australia', 'recent', 'legal', 'gay', 'marriag']\n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "\n",
    "# import the library\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#print(type(snowball_stemmer))\n",
    "\n",
    "# list comprehension command\n",
    "# take each word that we have, take list and one after the other, teach each token and stem them\n",
    "\n",
    "stem_sentence = [snowball_stemmer.stem(word) for word in only_words_sentence]\n",
    "\n",
    "print (stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Jess/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "['sydney', 'rainbow', 'firework', 'sparkled', 'harbour', 'bridge', 'celebration', 'australia', 'recent', 'legalization', 'gay', 'marriage']\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "#from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemma_sent = [wordnet_lemmatizer.lemmatize(word) for word in only_words_sentence]\n",
    "\n",
    "print (lemma_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', ',', '2017', 'In', 'Sydney', ',', 'rainbow', 'fireworks', 'sparkled', 'off', 'the', 'Harbour', 'Bridge', 'in', 'celebration', 'of', 'Australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage', '.']\n"
     ]
    }
   ],
   "source": [
    "#POS tagging\n",
    "# http://www.nltk.org/book/ch05.html\n",
    "\n",
    "# we need to use the original sentence as a list of tokens; NO PREPROCCESSING AT ALL! Don't touch or remove anything when you do this\n",
    "\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Jess/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[('31', 'CD'), (',', ','), ('2017', 'CD'), ('In', 'IN'), ('Sydney', 'NNP'), (',', ','), ('rainbow', 'NN'), ('fireworks', 'NNS'), ('sparkled', 'VBD'), ('off', 'RP'), ('the', 'DT'), ('Harbour', 'NNP'), ('Bridge', 'NNP'), ('in', 'IN'), ('celebration', 'NN'), ('of', 'IN'), ('Australia', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('recent', 'JJ'), ('legalization', 'NN'), ('of', 'IN'), ('gay', 'JJ'), ('marriage', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# you use the pos-tagger (it gives you back a list of tuples (word,pos = part of speech))\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos_sentence = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "print (pos_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD\n",
      ",\n",
      "CD\n",
      "IN\n",
      "NNP\n",
      ",\n",
      "NN\n",
      "NNS\n",
      "VBD\n",
      "RP\n",
      "DT\n",
      "NNP\n",
      "NNP\n",
      "IN\n",
      "NN\n",
      "IN\n",
      "NNP\n",
      "NNP\n",
      "VBD\n",
      "JJ\n",
      "NN\n",
      "IN\n",
      "JJ\n",
      "NN\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for touple in pos_sentence:\n",
    "    print(touple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      ",\n",
      "2017\n",
      "in\n",
      "sydney\n",
      ",\n",
      "rainbow\n",
      "fireworks\n",
      "sparkled\n",
      "off\n",
      "the\n",
      "harbour\n",
      "bridge\n",
      "in\n",
      "celebration\n",
      "of\n",
      "australia\n",
      "’\n",
      "s\n",
      "recent\n",
      "legalization\n",
      "of\n",
      "gay\n",
      "marriage\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#print(type(pos_sentence[0]))\n",
    "#print(pos_sentence[0][0])\n",
    "\n",
    "for word,pos in pos_sentence:\n",
    "    word = word.lower()\n",
    "    print(word)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', ',', '2017', 'in', 'sydney', ',', 'rainbow', 'firework', 'sparkle', 'off', 'the', 'harbour', 'bridge', 'in', 'celebration', 'of', 'australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage', '.']\n"
     ]
    }
   ],
   "source": [
    "# combining lemmatization and pos tagging\n",
    "\n",
    "lemmas = []\n",
    "\n",
    "for word,pos in pos_sentence:\n",
    "    # we lower-case the word (for lemmatization)\n",
    "    word = word.lower()\n",
    "    \n",
    "    # if it's a verb - then we tell that to the lemmatizer\n",
    "    if \"V\" in pos:\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word, \"v\") # pos parameter = verb, default is set to noun\n",
    "    \n",
    "    else:\n",
    "    # otherwise, work as usual\n",
    "        lemma = wordnet_lemmatizer.lemmatize(word)\n",
    "    # we append the results\n",
    "    lemmas.append(lemma)\n",
    "\n",
    "print (lemmas)\n",
    "\n",
    "\n",
    "#homework - try to write this with a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31', ',', '2017', 'in', 'sydney', ',', 'rainbow', 'firework', 'sparkle', 'off', 'the', 'harbour', 'bridge', 'in', 'celebration', 'of', 'australia', '’', 's', 'recent', 'legalization', 'of', 'gay', 'marriage', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemmas = [wordnet_lemmatizer.lemmatize(touple[0].lower(), \"v\") if \"V\" in touple[1] else wordnet_lemmatizer.lemmatize(touple[0].lower()) for touple in pos_sentence]\n",
    "print(lemmas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
